<!DOCTYPE html>
<html>
<head>
  <meta name="generator" content="HTML Tidy for HTML5 for Linux version 5.2.0">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <title>tinySelf performance gains 2019/4</title>
  <link rel="stylesheet" type="text/css" href="../../../style.css">
  <link rel="alternate" type="application/atom+xml" href="https://blog.rfox.eu/atom.xml">
  <link rel="shortcut icon" href="/favicon.ico">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@Bystroushaak">
  <meta name="twitter:creator" content="@Bystroushaak">
  <meta name="twitter:title" content="tinySelf performance gains 2019/4">
  <meta name="twitter:description" content="Description of how I gained performance in my programming language tinySelf. Rpython profiling and optimizations.">
  <meta name="twitter:image" content="https://blog.rfox.eu/en/Programming/tinySelf/tinySelf_performance_gains_2019-4/profiling_thumb.jpg">
  <script src="../../../scripts.js">
  </script>
  <meta name="description" content="Description of how I gained performance in my programming language tinySelf. Rpython profiling and optimizations.">
  <meta name="keywords" content="tinyself,selflang,diy_programming_language,debugging,rpython,python,pypy"><!-- Global site tag (gtag.js) - Google Analytics -->

  <script src="https://www.googletagmanager.com/gtag/js?id=UA-142545439-1">
  </script>
  <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
    
      gtag('config', 'UA-142545439-1');
  </script>
</head>
<body onload="on_body_load();">
  <div id="sidebar_top">
    <span><a href="https://blog.rfox.eu/atom.xml"><img style="width: 3em;" src="../../../rss_icon.png"></a> &nbsp; &nbsp; <a href="https://twitter.com/Bystroushaak"><img style="width: 3em;" src="../../../twitter_icon.png"></a></span>
    <div id="last_five_top">
      <h3>New posts</h3>
      <ul>
        <li>
          <a href="../../../Paperclips/Things_that_disappeared/PyAtom_disappeared.html" title="PyAtom disappeared">PyAtom disappeared</a>
        </li>
        <li>
          <a href="../../3D_modeling/Microtron_model_progress_2020-12_Case_for_the_crystal.html" title="Microtron model progress 2020/12; Case for the crystal">Microtron model progress 2020/12; Case for the crystal</a>
        </li>
        <li>
          <a href="../../Hardware/Robots_Ive_played_with.html" title="Robots I've played with">Robots I've played with</a>
        </li>
        <li>
          <a href="../../Philosophy/Joscha_Bach_Artificial_Consciousness_and_the_Nature_of_Reality.html" title="Joscha Bach; Artificial Consciousness and the Nature of Reality">Joscha Bach; Artificial Consciousness and the Nature of Reality</a>
        </li>
        <li>
          <a href="../Tools_I_use/Tools_I_use_argparse_builder.html" title="Tools I use: argparse builder">Tools I use: argparse builder</a>
        </li>
        <li>
          <a href="../../3D_modeling/3D_Starship_in_the_Prague_cityscape.html" title="3D Starship in the Prague cityscape">3D Starship in the Prague cityscape</a>
        </li>
        <li>
          <a href="../../3D_modeling/3D_ePUB_icon_for_my_articles_about_Self.html" title="3D ePUB icon for my articles about Self">3D ePUB icon for my articles about Self</a>
        </li>
        <li>
          <a href="../../../Paperclips/Interesting_graffiti_Ive_seen.html" title="Interesting graffiti I've seen"><span class="icon">ğŸ—’ï¸</span>Interesting graffiti I've seen</a>
        </li>
        <li>
          <a href="../../Weekly_updates/Newsletter_2020-09-12_Waves_of_productivity.html" title="Newsletter 2020-09-12; Waves of productivity">Newsletter 2020-09-12; Waves of productivity</a>
        </li>
        <li>
          <a href="../../../Paperclips/Rationality_From_AI_to_Zombies_as_on_demand_book.html" title="Rationality; From AI to Zombies as on demand book"><span class="icon">ğŸ—’ï¸</span>Rationality; From AI to Zombies as on demand book</a>
        </li>
      </ul>& <a href="../../../Changelog.html" title="Changelog">more</a>
    </div>
    <div>
      <h3>Tags</h3>
      <p><a href="../../../Tags/debugging.html" title="debugging">debugging</a>, <a href="../../../Tags/diy_programming_language.html" title="diy_programming_language">diy_programming_language</a>, <a href="../../../Tags/pypy.html" title="pypy">pypy</a>, <a href="../../../Tags/python.html" title="python">python</a>, <a href="../../../Tags/rpython.html" title="rpython">rpython</a>, <a href="../../../Tags/selflang.html" title="selflang">selflang</a>, <a href="../../../Tags/tinyself.html" title="tinyself">tinyself</a></p>
    </div>
    <div>
      <h3>Blog categories</h3>
      <ul class="no_icon">
        <li>
          <a href="../../Weekly_updates.html" title="Weekly updates">ğŸ“‚ Weekly updates</a>
        </li>
        <li>
          <a href="../../Programming.html" title="Programming">ğŸ“‚ Programming</a>
        </li>
        <li>
          <a href="../../Explorations.html" title="Explorations">ğŸ“‚ Explorations</a>
        </li>
        <li>
          <a href="../../3D_modeling.html" title="3D modeling">ğŸ“‚ 3D modeling</a>
        </li>
        <li>
          <a href="../../Improvements.html" title="Improvements">ğŸ“‚ Improvements</a>
        </li>
        <li>
          <a href="../../Data_hoarding.html" title="Data hoarding">ğŸ— Data hoarding</a>
        </li>
        <li>
          <a href="../../Technological_marvels.html" title="Technological marvels">ğŸ“‚ Technological marvels</a>
        </li>
        <li>
          <a href="../../Organization_of_information.html" title="Organization of information">ğŸ“‚ Organization of information</a>
        </li>
        <li>
          <a href="../../Books.html" title="Books">ğŸ“‚ Books</a>
        </li>
        <li>
          <a href="../../Hardware.html" title="Hardware">ğŸ“‚ Hardware</a>
        </li>
        <li>
          <a href="../../Philosophy.html" title="Philosophy">ğŸ“‚ Philosophy</a>
        </li>
        <li>
          <a href="../../About_this_blog.html" title="About this blog">ğŸ“‚ About this blog</a>
        </li>
        <li>
          <a href="../../index.html" title="English section">ğŸ“‚ English section</a>
        </li>
      </ul>
    </div>
  </div><a class="breadcrumb" href="../../../index.html" title="Bystroushaak's blog">Bystroushaak's blog</a> / <a class="breadcrumb" href="../../index.html" title="English section">English section</a> / <a class="breadcrumb" href="../index.html" title="Programming">Programming</a> / <a class="breadcrumb" href="index.html" title="tinySelf">tinySelf</a> / tinySelf performance gains 2019/4
  <article id="ef0d6334-f7fb-4256-a3f2-1cb90bd5db37" class="page sans">
    <header>
      <h1 class="page-title">tinySelf performance gains 2019/4</h1>
    </header>
    <div class="page-body">
      <p id="0eb58ed8-37a9-40a2-a6d7-8e6e4b012a46" class=""><time>@2019/04/19</time></p>
      <p id="4699104b-7673-4494-8e66-0055904745a0" class=""><a href="https://github.com/Bystroushaak/tinySelf">tinySelf</a> is my pet programming language inspired by Self, which I am writing in my spare time. It was slow, so I've decided to speed it up a little. Last time (<a href="Speedups_of_the_interpreter_2019-1.html" title="Speedups of the interpreter 2019/1">Speedups of the interpreter 2019/1</a>) was a massive success in term of speed gains, so I've had high hopes.</p>
      <p id="3906e0ab-4c36-43be-b49d-ae80fe864731" class="">First of all, I've decided to run another profiling with callgrind. Here is the result from the profiler:</p>
      <figure id="5ede41ca-f8df-47de-b053-863b78d01484">
        <div class="source">
          <a href="tinySelf_performance_gains_2019-4/callgrind.out.16306" title="callgrind.out.16306">https://s3-us-west-2.amazonaws.com/secure.notion-static.com/2035139e-e82e-42b0-a03f-7e7117c3dd24/callgrind.out.16306</a>
        </div>
      </figure>
      <p id="94a8fab5-4767-4c3e-9538-75fd6c43f068" class="">Unsurprisingly, it can be seen from the first glance, that 73.45% of the time is spent in the <code>_do_send()</code> method:</p>
      <figure id="c634c802-ed5d-434c-9274-8c7313ba12b4" class="image">
        <a href="tinySelf_performance_gains_2019-4/profiling.png" title="profiling.png"><img style="width:2560px" src="tinySelf_performance_gains_2019-4/profiling_thumb.jpg"></a>
      </figure>
      <p id="44de260b-12b5-429c-ba0a-aa6176e0c223" class="">42% takes slot lookup, which is not much surprising. 34% of that takes parent lookup. Still, no surprise there.</p>
      <p id="d411c9dd-8339-4dcb-a948-240befb208ef" class="">A lot takes <code>_create_intermediate_params_obj()</code>. That kind of surprised me, because it was already optimized once. I will have to devise some method of caching of the parameters, maybe in the code context or something.</p>
      <figure class="block-color-gray_background callout" id="038219f5-e8a9-4f94-abcb-053cee87dc93" style="display:flex">
        <div style="font-size:1.5em">
          <span class="icon">âš ï¸</span>
        </div>
        <div style="width:100%">
          I am using several computers for development, from my notebook to my desktop, so don't look at the time in <code>perf</code> outputs, but at the number of crunched instructions.
        </div>
      </figure>
      <h1 id="5645b496-f4eb-49c3-a06b-155db1aacdf7" class="">Intermediate parent lookup cache</h1>
      <p id="c21893f9-50cf-430d-8d3d-171430b0f516" class="">This was the first optimization which I've begun to implement. It has to do with mechanism how are parameters mapped to namespace of method calls.</p>
      <p id="42ce8da1-e9d1-492a-bf1b-a8c087479408" class="">Each time the <code>_do_send()</code> method is invoked and the message send results in code object, <code>_push_code_obj_for_interpretation()</code> method is called, which in turn calls Tail Call Optimization check and method <code>_create_intermediate_params_obj()</code>, used to map all parameters into one parent, which is then mounted as <code>scope_parent</code> for code object pushed at the top of the stack.</p>
      <p id="3f101672-0d66-46f6-a30b-ff539aabaca5" class="">There is already some caching going on, to not to create empty parents with parameters, as it massively slows the interpreter when tail call optimization is working, but in case that this is not a recursive call, it still creates new objects for parameters. This is usually not an issue, but in while loops, new blocks are initialized and new objects for parameters are created in each loop.</p>
      <p id="99e634e5-e732-4cc4-86ab-2ca80aac2cb2" class="">Obvious solution is to cache the parameter object map for each block / code object call and create only clone.</p>
      <p id="95897a21-2d5e-4ff4-8582-d4c9a0d02edf" class="">So I've implemented it, but measuring the speed by time did not result into conclusive results. It looked like nothing improved.</p>
      <p id="afbfc6d6-497b-49e8-b062-5b0779524ee4" class="">I've realized, that I need some better tool than just measuring with <code>time</code>, because there is really a lot of stuff running in the background. I would like to see some more "scientific" results, like for example number of instructions that was executed.</p>
      <p id="380c8430-ae3e-4484-be59-a60936adc3d3" class="">Quick search on the google showed me that I can use <code>perf stat</code>.</p>
      <p id="f01c13e2-cd98-4371-a189-37c8bced8dcc" class="">Results for code without the new optimization:</p>
      <pre id="8f9b1053-012d-4042-bf72-8f371872d778" class="code"><code>$ sudo perf stat ./tSelf tests/scripts/simple_while_benchmark.self 
4.676559

 Performance counter stats for './tSelf tests/scripts/simple_while_benchmark.self':

       4639,594198      task-clock (msec)         #    0,987 CPUs utilized          
                55      context-switches          #    0,012 K/sec                  
                 0      cpu-migrations            #    0,000 K/sec                  
             9â€¯863      page-faults               #    0,002 M/sec                  
    12â€¯882â€¯386â€¯678      cycles                    #    2,777 GHz                    
    28â€¯716â€¯919â€¯724      instructions              #    2,23  insn per cycle         
     5â€¯525â€¯961â€¯270      branches                  # 1191,044 M/sec                  
        17â€¯527â€¯128      branch-misses             #    0,32% of all branches        

       4,700498870 seconds time elapsed</code></pre>
      <p id="7f49e3d4-7dff-454a-90bd-ab8c30ea2d10" class="">And for the version with new optimization:</p>
      <pre id="5ff10024-22c2-43de-89bd-dcd42ce30618" class="code"><code> Performance counter stats for './otSelf tests/scripts/simple_while_benchmark.self':

       4886,654256      task-clock (msec)         #    0,986 CPUs utilized          
                57      context-switches          #    0,012 K/sec                  
                 3      cpu-migrations            #    0,001 K/sec                  
             8â€¯523      page-faults               #    0,002 M/sec                  
    13â€¯340â€¯962â€¯314      cycles                    #    2,730 GHz                    
    29â€¯316â€¯255â€¯135      instructions              #    2,20  insn per cycle         
     5â€¯641â€¯543â€¯528      branches                  # 1154,480 M/sec                  
        15â€¯815â€¯261      branch-misses             #    0,28% of all branches        

       4,957247412 seconds time elapsed</code></pre>
      <p id="8b80097b-39ba-4a84-840e-1017ab0a3714" class="">Time is not that important, as it was different each time a and sometimes one was faster than the other just to switch again in next measurement.</p>
      <p id="f894d67c-02fe-4b02-bab1-117169cf9ddb" class="">But overall, yeah, it is worse with new optimization. I find it quite horrible that 1 000 000 increments takes 29â€¯316â€¯255â€¯135 instructions (29316 for one loop cycle), even tho that there is multiple blocks/lambdas evaluate the result and everything is highly dynamic.</p>
      <p id="8a44dd03-face-43c8-b1a6-1c8ddf0cbcc4" class="">Why is it slower? Some investigation showed that the code still creates new maps when using cached value, because <em>only in some cases</em> it writes <code>*</code> parent into it and that triggers the new map creation for the cloned object, because cloned version was structurally changed. I am trying to cache object which sometimes structurally changes, and that is obviously nonsense.</p>
      <p id="0298bba8-cfdc-4159-a55b-3203c8693fca" class="">So, nope, wrong idea, time for rollback. At least I've found out and fixed one bug. Current status 28G7.</p>
      <h1 id="ccf759c8-4513-4831-a032-cb2d1e29dc9c" class="">Block traits</h1>
      <p id="74cac813-f2b5-4250-8774-6727d760a2c4" class="">This is an idea of the same kind as previous optimization, but for blocks. Block trait parents are created dynamically every time block object is used. So cache them for each code context, as block's code context is called many times during each <code>while</code> cycle.</p>
      <pre id="d7fede33-2fa4-48f0-93ca-38fc72a95ca7" class="code"><code> Performance counter stats for './tSelf tests/scripts/simple_while_benchmark.self':

       4063,963996      task-clock (msec)         #    0,995 CPUs utilized          
                16      context-switches          #    0,004 K/sec                  
                 1      cpu-migrations            #    0,000 K/sec                  
             8â€¯240      page-faults               #    0,002 M/sec                  
    11â€¯404â€¯916â€¯268      cycles                    #    2,806 GHz                    
    27â€¯102â€¯974â€¯881      instructions              #    2,38  insn per cycle         
     5â€¯242â€¯774â€¯320      branches                  # 1290,064 M/sec                  
        15â€¯914â€¯696      branch-misses             #    0,30% of all branches</code></pre>
      <p id="7840db24-c261-4c4f-a20a-5c39e7861bdb" class="">Such simple optimization reduced number of instruction to 27G1! That's 1 613 944 843 fewer instructions per one million while cycles. Nice.</p>
      <h1 id="f20548cc-a134-42aa-942c-898d9a43c66e" class="">Random optimization</h1>
      <p id="01fbeacf-20db-43c9-8ab4-1c3903cef11a" class="">I was giving another shot to optimization with <em>Intermediate parent lookup cache</em>, and I've rewritten <code>._put_together_parameters()</code> to generator instead of function returning array. Quite surprisingly, it was suddenly slightly faster:</p>
      <pre id="9c850e24-69f9-4f8c-9088-4911ef034458" class="code"><code> Performance counter stats for './tSelf tests/scripts/simple_while_benchmark.self':

       3262,042236      task-clock (msec)         #    0,993 CPUs utilized          
                 8      context-switches          #    0,002 K/sec                  
                 1      cpu-migrations            #    0,000 K/sec                  
            15â€¯792      page-faults               #    0,005 M/sec                  
    11â€¯602â€¯925â€¯303      cycles                    #    3,557 GHz                    
    26â€¯936â€¯652â€¯659      instructions              #    2,32  insn per cycle         
     5â€¯190â€¯354â€¯343      branches                  # 1591,136 M/sec                  
        12â€¯945â€¯940      branch-misses             #    0,25% of all branches</code></pre>
      <p id="2d953d99-3847-4a97-8f98-caac3777c35e" class="">26G9 out of random.</p>
      <h1 id="4794d1a5-c778-453e-8c81-df6450d5a1e6" class="">Rewrite set / dict to list</h1>
      <p id="a8d3c129-c730-41af-a085-649b7824c1d0" class="">When I was attempting yet another attempt to optimize <em>Intermediate parent lookup cache</em>, I've rewritten <code>_visited_objects</code> variable in <code>Object.parent_lookup()</code> from RPython's sets (dicts with <code>None</code> as value) to <code>list</code>, because the set was just old relic. I really just needed container to store objects for later, when I will unvisit them (set all <code>.visited</code> properties back to <code>False</code>).</p>
      <p id="fd613424-7775-4add-a66b-d0fff243e50c" class="">This resulted in nice speedup:</p>
      <pre id="21046fb4-1018-4345-a0dd-fffddc5d58e2" class="code"><code>       2903,254674      task-clock (msec)         #    0,994 CPUs utilized          
                 7      context-switches          #    0,002 K/sec                  
                 0      cpu-migrations            #    0,000 K/sec                  
             2â€¯232      page-faults               #    0,769 K/sec                  
    10â€¯387â€¯334â€¯274      cycles                    #    3,578 GHz                    
    25â€¯032â€¯972â€¯112      instructions              #    2,41  insn per cycle         
     4â€¯838â€¯632â€¯101      branches                  # 1666,623 M/sec                  
        11â€¯633â€¯578      branch-misses             #    0,24% of all branches</code></pre>
      <p id="f2b27b23-cdc3-421f-a9bc-6083df9b3284" class="">25G this simple. Wow.</p>
      <h1 id="086c3371-0c0a-43fe-8a59-16c8901d5282" class="">Intermediate parent lookup cache attempt n. 3</h1>
      <p id="9e72a455-ae45-470f-b651-d66d662e7d31" class="">As I said in previous sub-chapter, I was attempting another try at the <em>Intermediate parent lookup cache</em> optimization.</p>
      <pre id="70b14d40-8647-4789-b2a0-10742a725b08" class="code"><code>       2794,943301      task-clock (msec)         #    0,993 CPUs utilized          
                13      context-switches          #    0,005 K/sec                  
                 2      cpu-migrations            #    0,001 K/sec                  
             1â€¯661      page-faults               #    0,594 K/sec                  
     9â€¯921â€¯690â€¯448      cycles                    #    3,550 GHz                    
    23â€¯893â€¯490â€¯688      instructions              #    2,41  insn per cycle         
     4â€¯657â€¯628â€¯104      branches                  # 1666,448 M/sec                  
        13â€¯391â€¯723      branch-misses             #    0,29% of all branches</code></pre>
      <p id="c5bba284-234c-4fde-9769-a30665bf75ba" class="">And this time, it looks like I've done it; 23G9 instructions!</p>
      <h1 id="582e03cc-7ba5-4ac5-b793-b0612c890f1a" class="">Dynamic recompilation</h1>
      <p id="864ead2a-0d4d-4173-9e41-8025cdacbe2a" class="">Okay, so I've created new branch to implement dynamic recompilation of the bytecode, where the idea is following:</p>
      <p id="1382dd4c-96ba-4743-b5b5-0230b804cbe4" class="">When resolving local slots, instead of lookups to the slot dictionary, which is by itself just index table indirection to <code>._slot_values</code> property of the object, recompile the bytecode in such way that whole sequence of PUSH_LITERAL and SEND bytecodes is replaced by LOCAL_SEND bytecode.</p>
      <p id="2baef733-6e24-484c-9093-6f4a5466b598" class="">This not only saves time because PUSH_LITERAL is skipped, but also removes the name resolution / dict lookup in <code>obj.map._slots</code> in SEND instruction.</p>
      <p id="19fa38bf-9fb4-4c33-99cf-d3f3fe86fcf4" class="">Off course, this is not really that great time saving for local sends, but it may be great for parent sends, because it potentially saves a lot of requests to several dictionaries in parents. Local sends are still great for proof of concept.</p>
      <figure id="d6d5bed3-db1b-4692-ab8c-a72dc6157829" class="image">
        <a href="tinySelf_performance_gains_2019-4/2019-04-16_19.58.16.png" title="2019-04-16_19.58.16.png"><img style="width:2798px" src="tinySelf_performance_gains_2019-4/2019-04-16_19.58.16_thumb.jpg"></a>
      </figure>
      <p id="35f050cf-538a-4eb4-bcac-701385ee0488" class="">So, I had to put some kind of measurement into the <code>object_layout.py</code>, as it only makes sense to dynamically recompile objects which already have some slots.</p>
      <figure id="e44716b6-ee1d-41ef-8c76-106292528907" class="image">
        <a href="tinySelf_performance_gains_2019-4/2019-04-16_19.59.32.png" title="2019-04-16_19.59.32.png"><img style="width:2999px" src="tinySelf_performance_gains_2019-4/2019-04-16_19.59.32_thumb.jpg"></a>
      </figure>
      <p id="b5637471-ce5c-456d-898a-1b485551bbfa" class="">I've implemented all this, introduced new bytecodes for local and parent sends, then split <code>._do_send()</code> method into multiple parts, which were used by new bytecodes. And it worked and it was <em>slightly</em> faster.</p>
      <p id="b804d6b2-a06f-4a25-9edc-a1d002e8d685" class="">Then I've implemented parent caches as dicts, so it was remembered what object was resolved, and then I've rewritten parent lookups to save results to this cache, but also store <em>versions</em> of whole parent tree. This is necessary, because you have to invalidate parent lookup cache when something in the tree changes. Then I've added dynamic recompilation for parents and it actually worked.</p>
      <p id="6ff57abf-29cd-4b39-89d2-f93c28a968bd" class="">In theory, this should have been faster, but it wasn't:</p>
      <pre id="28ab2fcd-75e2-4880-abd0-c7d95938b877" class="code"><code>       2694,114612      task-clock (msec)         #    0,993 CPUs utilized          
                 8      context-switches          #    0,003 K/sec                  
                 0      cpu-migrations            #    0,000 K/sec                  
             1â€¯715      page-faults               #    0,637 K/sec                  
     9â€¯767â€¯838â€¯987      cycles                    #    3,626 GHz                    
    24â€¯752â€¯967â€¯353      instructions              #    2,53  insn per cycle         
     4â€¯735â€¯181â€¯543      branches                  # 1757,602 M/sec                  
        11â€¯451â€¯403      branch-misses             #    0,24% of all branches</code></pre>
      <p id="0669106c-937f-482f-8d44-aebc01b4f723" class="">I've spent afternoon debugging the code, when I've noticed that some object in parent tree is almost always changed and this triggers cache invalidation and recompilation in each cycle. This was annoying, code was complex, so I've thrown most of it out.</p>
      <p id="ccdfcd7f-61c6-4fbe-be5a-251551f7f96c" class="">This may seem like it was premature decision, but there were also problems with inlined bytecode invalidation and switching back to unoptimized bytecodes, because the optimized code had to be padded with <code>NOP</code>s in places where <code>PUSH_LITERAL</code> instructions were, and switch back to unoptimized code could wreak havoc in <code>MethodStack</code>, when nested calls occurred.</p>
      <p id="70d0eaf7-7192-4870-b941-6cc882983f40" class="">You can see the code in the <a href="https://github.com/Bystroushaak/tinySelf/blob/1a1f6d2a76c4e42fee4287b6d80e0ba2b49291f9/src/tinySelf/vm/dynamic_recompiler.py">dynamic_recompiler.py</a> in <a href="https://github.com/Bystroushaak/tinySelf/tree/local_send_cache">local_send_cache</a> branch.</p>
      <h1 id="46946e4e-26f8-4254-bfea-0d741f1aa5fe" class="">LightWeightDict</h1>
      <p id="10cbe67c-244d-4878-915e-9004c4604da1" class="">In the process of writing dynamic recompiler, I had a revelation, that dict lookup is not that costly, it is just dict creation which is slow. So I've decided to implement my own wrapper class, which implements dict-like interface and uses three properties to store values. Only when there are more than three values stored in the dict, it uses list for 8 values and only when there is more than that, it switches back to regular dict.</p>
      <p id="1ddb4ed6-37b7-4866-9561-e98e6d3f3e6a" class="">I've also decided to switch to full tree search in parent lookups, as that is only correct way, otherwise you can have nasty runtime errors (as <em>David Ungar</em> says in one of many papers about Self he published).</p>
      <p id="a89645fd-f0f4-4766-9fd6-93db49d47a8e" class="">Sadly, I don't have exact numbers, but it was slightly (something around 300M instructions) faster. And then I created version with preallocated lists and that was also faster.</p>
      <h1 id="73bc718a-4a23-4000-9653-7da8e75d6d61" class="">Preallocated lists</h1>
      <p id="1fd8a227-21b3-4b39-a4a0-d2aadfc9abb2" class="">Parent lookup algorithm uses lists to iterate, and to append to one list called <code>objects</code>, from which it pops in each iteration. Then there is second list <code>visited_objects</code>, where all visited objects are stored so algorithm can `unvisit` them after it finishes the graph lookup.</p>
      <p id="20055582-2355-438d-9419-f7db05e01a59" class="">Both lists are used only once, and are not used for lookups, mode of operation is much more suited for FIFO queue. This lead me to attempt to optimize the algorithm with preallocated array and set of pointers to list:</p>
      <pre id="8b656f32-3d4a-4351-92d3-075547c06eb9" class="code"><code>class TwoPointerArray(object):
    def __init__(self, length):
        self._length = length
        self._array = [None for _ in xrange(length)]
        self._left_pointer = 0
        self._right_pointer = 0

    def __len__(self):
        return self._right_pointer - self._left_pointer

    def __getitem__(self, index):
        return self._array[self._left_pointer + index]

    def __setitem__(self, key, value):
        self._array[key] = value

    def pop_first(self):
        if self._left_pointer == self._right_pointer:
            raise IndexError()

        rval = self._array[self._left_pointer]
        self._array[self._left_pointer] = None
        self._left_pointer += 1
        return rval

    def pop_last(self):
        if self._left_pointer == self._right_pointer:
            raise IndexError()

        rval = self._array[self._right_pointer - 1]
        self._array[self._right_pointer - 1] = None
        self._right_pointer -= 1
        return rval

    def append(self, item):
        if self._right_pointer &gt;= self._length:
            self._array.append(item)
            self._right_pointer += 1
            self._length += 1
            return

        self._array[self._right_pointer] = item
        self._right_pointer += 1

    def to_list(self):
        return self._array[self._left_pointer: self._right_pointer]</code></pre>
      <p id="4ba6be05-d0df-40cd-8f3b-36f00cf312e8" class="">Python's lists should be preallocated under RPython, but I've found that my version has huge performance gains:</p>
      <pre id="caf58960-3db3-421e-a751-425a68e36799" class="code"><code>       3239,654852      task-clock (msec)         #    0,994 CPUs utilized          
                 9      context-switches          #    0,003 K/sec                  
                 1      cpu-migrations            #    0,000 K/sec                  
             3â€¯803      page-faults               #    0,001 M/sec                  
     9â€¯196â€¯081â€¯084      cycles                    #    2,839 GHz                    
    20â€¯420â€¯359â€¯470      instructions              #    2,22  insn per cycle         
     4â€¯064â€¯685â€¯697      branches                  # 1254,666 M/sec                  
         6â€¯971â€¯611      branch-misses             #    0,17% of all branches </code></pre>
      <p id="d9c50999-0df4-426d-bd10-0425530f636f" class="">20G4, that's 4G3 instructions less just with this simple optimization.</p>
      <h1 id="d6403df0-68d5-4f45-bb80-509a055c2ee5" class="">Parent lookup cache</h1>
      <p id="cc1731b5-3560-46de-823b-2abdc0baefa5" class="">I've decided to give another try to parent cache, that is the dict based cache for parent lookups.</p>
      <p id="75814c35-7d38-4ce1-acbf-e175203624cb" class="">First I've implemented object version stored in <code>.map._version</code> property as numeric int. Each meta-operation, like setting a new content of slot, or adding or removing slot, increments the version.</p>
      <p id="d4ef7f8f-e9ee-4d2e-9b02-ebd218766d38" class="">When a parent lookup is performed, algorithm goes over whole graph of parents, marks objects as <code>.visited=True</code>, and then stores the list of all objects in variable <code>visited_objects</code>, which is then iterated and each object is then unvisited.</p>
      <p id="22131133-bf8b-48db-aac4-4937acc68081" class="">I've added cache in format <code>{"slot_name": [result, [VersionedObject(x) for x in visited_objects]]}</code>. That is <code>.visited_objects</code> is stored in wrapper class with their current version.</p>
      <p id="1b2a9b4a-a959-4097-8d9b-3440891e79c2" class="">When the parent lookup request is performed next time, all versions are compared and only those objects which changed are used for lookup algorithm. This resulted in 1G8 less instructions:</p>
      <pre id="f9294c79-b2a7-4791-abb7-a4bc0f7e4d14" class="code"><code>       2908,278592      task-clock (msec)         #    0,992 CPUs utilized          
                 8      context-switches          #    0,003 K/sec                  
                 0      cpu-migrations            #    0,000 K/sec                  
             3â€¯709      page-faults               #    0,001 M/sec                  
     8â€¯496â€¯614â€¯780      cycles                    #    2,922 GHz                    
    18â€¯645â€¯475â€¯253      instructions              #    2,19  insn per cycle         
     3â€¯584â€¯880â€¯617      branches                  # 1232,647 M/sec                  
         7â€¯969â€¯234      branch-misses             #    0,22% of all branches</code></pre>
      <h1 id="45f4ee75-4bc7-49a3-b345-0735fa5bf368" class="">Rewrite stack / frames to linked lists</h1>
      <p id="987bd0c2-dc02-4ab2-9bc2-172295651e76" class="">All kind of stacks were implemented as lists, which were <code>.append()</code>-ed and <code>.pop()</code>-ed. Simple rewrite to linked list provided significant performance boost:</p>
      <pre id="eb31b76f-f9c8-4a76-9ba4-7dc68f76c947" class="code"><code>       2607,500168      task-clock (msec)         #    0,984 CPUs utilized          
               418      context-switches          #    0,160 K/sec                  
                 1      cpu-migrations            #    0,000 K/sec                  
             3â€¯688      page-faults               #    0,001 M/sec                  
     7â€¯602â€¯782â€¯564      cycles                    #    2,916 GHz                    
    16â€¯544â€¯264â€¯590      instructions              #    2,18  insn per cycle         
     3â€¯225â€¯193â€¯435      branches                  # 1236,891 M/sec                  
         5â€¯024â€¯868      branch-misses             #    0,16% of all branches</code></pre>
      <p id="2342ecdc-847c-4f9f-b767-fdb515957195" class="">16G5, that is 2G1 fewer instructions per benchmark.</p>
      <h1 id="3fc70fd2-c69b-4929-9a53-6908d163233e" class="">#pypy help</h1>
      <p id="cf285664-179b-4cee-b35f-1ef4bd11d9a6" class="">I've asked what are people using for profiling on <code>#pypy</code> IRC channel and <a href="https://github.com/cfbolz">cfbolz</a> took interest in my interpreter and <a href="https://github.com/Bystroushaak/tinySelf/pull/95">pushed</a> some JIT hints. JIT wasn't until this point much useful for me, but with his changes, wow:</p>
      <pre id="0ea8894e-f723-47d9-923b-f395f8349d39" class="code code-wrap"><code>        979,203041      task-clock (msec)         #    0,981 CPUs utilized          
                 3      context-switches          #    0,003 K/sec                  
                 1      cpu-migrations            #    0,001 K/sec                  
             2â€¯194      page-faults               #    0,002 M/sec                  
     2â€¯813â€¯573â€¯468      cycles                    #    2,873 GHz                    
     6â€¯730â€¯985â€¯108      instructions              #    2,39  insn per cycle         
     1â€¯431â€¯479â€¯384      branches                  # 1461,882 M/sec                  
           533â€¯154      branch-misses             #    0,04% of all branches</code></pre>
      <p id="0ce4f934-a8c6-4681-9a0c-e44496b26cd1" class="">Whole benchmark now runs under one second with JIT.</p>
      <h1 id="7e0096e8-50f9-4658-9b95-39fb0d2999cf" class="">Rewrite method stack to preallocated list</h1>
      <p id="5a70a4e4-bb66-41e5-92d9-c279ae044d40" class="">I've also added version of <code>MethodStack</code> with preallocated list, as I know how many items will be on each method stack from the number of literals in that object. This indeed resulted in slightly faster code, but performance under JIT was slightly slower (around 7G3 instructions compared to 6G7 with linked lists).</p>
      <pre id="93d532f6-2e65-4127-9eb5-a00e712e38e0" class="code"><code>       1888,295288      task-clock (msec)         #    0,990 CPUs utilized          
                 8      context-switches          #    0,004 K/sec                  
                 0      cpu-migrations            #    0,000 K/sec                  
             1â€¯619      page-faults               #    0,857 K/sec                  
     6â€¯736â€¯850â€¯842      cycles                    #    3,568 GHz                    
    16â€¯131â€¯116â€¯476      instructions              #    2,39  insn per cycle         
     3â€¯215â€¯702â€¯497      branches                  # 1702,966 M/sec                  
         2â€¯876â€¯745      branch-misses             #    0,09% of all branches        

       1,907438730 seconds time elapsed</code></pre>
      <h1 id="393107ba-af9c-4cc9-b254-42480f8e7103" class="">Remove pre-initialization of slots and parents</h1>
      <p id="c9910934-8ef6-46ba-b89e-417ca611bed5" class="">As it was implemented, <code>__init__()</code> method of <code>Object</code> looked like this:</p>
      <pre id="47619dd2-1534-47c0-91f3-88bbbb20de54" class="code code-wrap"><code>    def __init__(self, map=None):
        self.map = map
        self.scope_parent = None
        self._slot_values = []
        self._parent_slot_values = []</code></pre>
      <p id="b7e6d67a-8016-4f6d-8224-746dff13d476" class="">That means the properties <code>._slot_values</code> and <code>._parent_slot_values</code> were initialized to empty lists. Simply changing them to <code>None</code> and initializing them lazily only when they are used changed performance significantly:</p>
      <pre id="06be27b3-d849-4c55-9bfc-80478b663068" class="code code-wrap"><code>       2174,622775      task-clock (msec)         #    0,991 CPUs utilized          
                19      context-switches          #    0,009 K/sec                  
                 1      cpu-migrations            #    0,000 K/sec                  
             1â€¯540      page-faults               #    0,708 K/sec                  
     5â€¯970â€¯301â€¯961      cycles                    #    2,745 GHz                    
    14â€¯764â€¯994â€¯336      instructions              #    2,47  insn per cycle         
     2â€¯942â€¯506â€¯811      branches                  # 1353,111 M/sec                  
         4â€¯412â€¯469      branch-misses             #    0,15% of all branches        

       2,194327578 seconds time elapsed</code></pre>
      <h1 id="092e1079-a1d9-4417-bfbc-c89773a9f775" class="">Different kinds of LightWeightDict</h1>
      <p id="c88d76a0-4e79-4e7c-b0c3-065649bcb53b" class="">I've decided it is time to measure different kinds of LightWeightDict:</p>
      <figure id="7866f08c-2484-4312-85dc-3586c8acadaa">
        <div class="source">
          <a href="tinySelf_performance_gains_2019-4/different_kind_of_lightweightdict.txt" title="different_kind_of_lightweightdict.txt">https://s3-us-west-2.amazonaws.com/secure.notion-static.com/67788e0b-72af-41ff-9545-13a947661df4/different_kind_of_lightweightdict.txt</a>
        </div>
      </figure>
      <p id="82ccc20d-b057-4a9a-98ce-9180c97cae99" class="">I've got one that uses dynamic arrays, one that uses statically allocated array before it switches to dicts internally and several versions of one which uses just number of properties (1-8) before it used internal dictionary to store data.</p>
      <p id="89ab472b-8f3a-4266-88e1-1ead6c4be837" class="">Results clearly show, that one that uses three properties and then fallback to dict is fastest.</p>
      <pre id="e3f42558-8a6a-4395-988a-ed0c5ca63b29" class="code code-wrap"><code>       1634,048187      task-clock (msec)         #    0,989 CPUs utilized
                 3      context-switches          #    0,002 K/sec
                 0      cpu-migrations            #    0,000 K/sec
             1â€¯407      page-faults               #    0,861 K/sec
     5â€¯922â€¯070â€¯772      cycles                    #    3,624 GHz
    14â€¯590â€¯886â€¯554      instructions              #    2,46  insn per cycle
     2â€¯927â€¯349â€¯398      branches                  # 1791,471 M/sec
         3â€¯116â€¯034      branch-misses             #    0,11% of all branches

       1,652842120 seconds time elapsed</code></pre>
      <p id="0a768b04-e4ea-4c3a-8858-a20fda01fd3f" class="">and with JIT:</p>
      <pre id="91b3c9ed-1c92-4f26-beb0-45c8b459fc03" class="code code-wrap"><code>        780,210821      task-clock (msec)         #    0,977 CPUs utilized          
                 6      context-switches          #    0,008 K/sec                  
                 0      cpu-migrations            #    0,000 K/sec                  
             2â€¯058      page-faults               #    0,003 M/sec                  
     2â€¯683â€¯932â€¯130      cycles                    #    3,440 GHz                    
     6â€¯062â€¯913â€¯589      instructions              #    2,26  insn per cycle         
     1â€¯312â€¯432â€¯517      branches                  # 1682,151 M/sec                  
           460â€¯458      branch-misses             #    0,04% of all branches        

       0,798466234 seconds time elapsed</code></pre>
      <p id="61b3fe07-deab-44ac-9450-d02bdbe198e5" class="">So final numbers are 14G6 without JIT and 6G with JIT.</p>
      <h1 id="ab9f6fb0-91b8-400e-a3e0-01c5b7517055" class="">Additional speedups</h1>
      <p id="1aee3edc-7b59-47fa-92af-ce47e3615783" class="">I am quite happy with the speed now, as it is finally usable, so I won't pursue another speedups for some time, and instead I will focus on features. <em>cfbolz</em> mentioned, that there are still possibilities of at least 10x performance speedup from just JIT itself.</p>
      <p id="57ce32b4-567e-4b3a-a7ea-e52d1ef2e548" class="">From the top of my head, there is also at least following possible speedups:</p>
      <ul id="f9a3f274-4a71-42b5-a16d-8e5eaa40a294" class="to-do-list">
        <li>
          <div class="checkbox checkbox-off"></div><span class="to-do-children-unchecked">Use hierarchical parent cache.</span>
        </li>
      </ul>
      <ul id="1409e235-0d67-4692-a9e5-e3d71eb53f29" class="to-do-list">
        <li>
          <div class="checkbox checkbox-off"></div><span class="to-do-children-unchecked">Optimize primitive types to be more effective.</span>
        </li>
      </ul>
      <ul id="b59b31de-3dbb-44ef-8011-445168384691" class="to-do-list">
        <li>
          <div class="checkbox checkbox-off"></div><span class="to-do-children-unchecked">Special versions of instructions ignoring the stack and using literals directly.</span>
        </li>
      </ul>
      <h1 id="d5849ef5-c40f-487e-8ca1-105403c925fb" class="">Relevant discussions</h1>
      <ul id="d33f41b0-c234-4d7b-ad5b-16be80bd3b5d" class="bulleted-list">
        <li>
          <a href="https://lobste.rs/s/haodba/tinyself_performance_gains_2019_4">https://lobste.rs/s/haodba/tinyself_performance_gains_2019_4</a>
        </li>
      </ul>
    </div>
  </article>
  <div class="corner-ribbon top-right red">
    <a href="https://www.patreon.com/bePatron?u=2618881">Become a Patron</a>
  </div><a class="twitter-share-button" id="twitter_button" href="#"><img src="../../../tweet_button.svg"></a>
  <div id="sidebar_bottom">
    <span><a href="https://blog.rfox.eu/atom.xml"><img style="width: 3em;" src="../../../rss_icon.png"></a> &nbsp; &nbsp; <a href="https://twitter.com/Bystroushaak"><img style="width: 3em;" src="../../../twitter_icon.png"></a></span>
    <div id="last_five_bottom">
      <h3>New posts</h3>
      <ul>
        <li>
          <a href="../../../Paperclips/Things_that_disappeared/PyAtom_disappeared.html" title="PyAtom disappeared">PyAtom disappeared</a>
        </li>
        <li>
          <a href="../../3D_modeling/Microtron_model_progress_2020-12_Case_for_the_crystal.html" title="Microtron model progress 2020/12; Case for the crystal">Microtron model progress 2020/12; Case for the crystal</a>
        </li>
        <li>
          <a href="../../Hardware/Robots_Ive_played_with.html" title="Robots I've played with">Robots I've played with</a>
        </li>
        <li>
          <a href="../../Philosophy/Joscha_Bach_Artificial_Consciousness_and_the_Nature_of_Reality.html" title="Joscha Bach; Artificial Consciousness and the Nature of Reality">Joscha Bach; Artificial Consciousness and the Nature of Reality</a>
        </li>
        <li>
          <a href="../Tools_I_use/Tools_I_use_argparse_builder.html" title="Tools I use: argparse builder">Tools I use: argparse builder</a>
        </li>
        <li>
          <a href="../../3D_modeling/3D_Starship_in_the_Prague_cityscape.html" title="3D Starship in the Prague cityscape">3D Starship in the Prague cityscape</a>
        </li>
        <li>
          <a href="../../3D_modeling/3D_ePUB_icon_for_my_articles_about_Self.html" title="3D ePUB icon for my articles about Self">3D ePUB icon for my articles about Self</a>
        </li>
        <li>
          <a href="../../../Paperclips/Interesting_graffiti_Ive_seen.html" title="Interesting graffiti I've seen"><span class="icon">ğŸ—’ï¸</span>Interesting graffiti I've seen</a>
        </li>
        <li>
          <a href="../../Weekly_updates/Newsletter_2020-09-12_Waves_of_productivity.html" title="Newsletter 2020-09-12; Waves of productivity">Newsletter 2020-09-12; Waves of productivity</a>
        </li>
        <li>
          <a href="../../../Paperclips/Rationality_From_AI_to_Zombies_as_on_demand_book.html" title="Rationality; From AI to Zombies as on demand book"><span class="icon">ğŸ—’ï¸</span>Rationality; From AI to Zombies as on demand book</a>
        </li>
      </ul>& <a href="../../../Changelog.html" title="Changelog">more</a>
    </div>
    <div>
      <h3>Tags</h3>
      <p><a href="../../../Tags/debugging.html" title="debugging">debugging</a>, <a href="../../../Tags/diy_programming_language.html" title="diy_programming_language">diy_programming_language</a>, <a href="../../../Tags/pypy.html" title="pypy">pypy</a>, <a href="../../../Tags/python.html" title="python">python</a>, <a href="../../../Tags/rpython.html" title="rpython">rpython</a>, <a href="../../../Tags/selflang.html" title="selflang">selflang</a>, <a href="../../../Tags/tinyself.html" title="tinyself">tinyself</a></p>
    </div>
    <div>
      <h3>Blog categories</h3>
      <ul class="no_icon">
        <li>
          <a href="../../Weekly_updates.html" title="Weekly updates">ğŸ“‚ Weekly updates</a>
        </li>
        <li>
          <a href="../../Programming.html" title="Programming">ğŸ“‚ Programming</a>
        </li>
        <li>
          <a href="../../Explorations.html" title="Explorations">ğŸ“‚ Explorations</a>
        </li>
        <li>
          <a href="../../3D_modeling.html" title="3D modeling">ğŸ“‚ 3D modeling</a>
        </li>
        <li>
          <a href="../../Improvements.html" title="Improvements">ğŸ“‚ Improvements</a>
        </li>
        <li>
          <a href="../../Data_hoarding.html" title="Data hoarding">ğŸ— Data hoarding</a>
        </li>
        <li>
          <a href="../../Technological_marvels.html" title="Technological marvels">ğŸ“‚ Technological marvels</a>
        </li>
        <li>
          <a href="../../Organization_of_information.html" title="Organization of information">ğŸ“‚ Organization of information</a>
        </li>
        <li>
          <a href="../../Books.html" title="Books">ğŸ“‚ Books</a>
        </li>
        <li>
          <a href="../../Hardware.html" title="Hardware">ğŸ“‚ Hardware</a>
        </li>
        <li>
          <a href="../../Philosophy.html" title="Philosophy">ğŸ“‚ Philosophy</a>
        </li>
        <li>
          <a href="../../About_this_blog.html" title="About this blog">ğŸ“‚ About this blog</a>
        </li>
        <li>
          <a href="../../index.html" title="English section">ğŸ“‚ English section</a>
        </li>
      </ul>
    </div>
  </div>
</body>
</html>
